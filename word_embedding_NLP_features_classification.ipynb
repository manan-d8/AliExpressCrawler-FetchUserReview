{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.15"
    },
    "colab": {
      "name": "word embedding_NLP_features_classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5FRuSmw9nI_",
        "colab_type": "text"
      },
      "source": [
        "This notebook is written to extracted several features from the text and then the extracted features are used to classify them into the given classes. The implementation is performed using the spam dataset. The participants have to use different datasets given in the Dataset folder and perform the classification. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxIMF63p-ujB",
        "colab_type": "text"
      },
      "source": [
        "You have to specify your own path where the code and datasets are present"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Oe99uTcvFkH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "598dbb8c-c8b6-4888-8b52-d81c2eccbbfd"
      },
      "source": [
        "import pandas as pd \n",
        "data =  pd.read_csv('SMSSpamCollection.csv', sep = '\\t', names = ['label', 'message'])\n",
        "data.head()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  label                                            message\n",
              "0   ham  Go until jurong point, crazy.. Available only ...\n",
              "1   ham                      Ok lar... Joking wif u oni...\n",
              "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3   ham  U dun say so early hor... U c already then say...\n",
              "4   ham  Nah I don't think he goes to usf, he lives aro..."
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56f1LdRYY4iq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = data['message']\n",
        "class_label = data['label']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CV5iAnlCdhZN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "classes_list = [\"ham\",\"spam\"]\n",
        "label_index = class_label.apply(classes_list.index)\n",
        "label = np.asarray(label_index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAZpYtCJdkT9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(text, label, test_size=0.33, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVeLdGr9doe5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "2f0b1248-564a-4c45-89c4-2f1d83b34fca"
      },
      "source": [
        "#!wget http://nlp.stanford.edu/data/glove.840B.300d.zip\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-08-26 05:38:45--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2020-08-26 05:38:45--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2020-08-26 05:38:46--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  1.81MB/s    in 6m 28s  \n",
            "\n",
            "2020-08-26 05:45:14 (2.12 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8B2uJXFehCH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "a457c246-7b3b-445b-b830-4a0e9a26de34"
      },
      "source": [
        "!unzip glove*.zip\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tEIjnT4elyj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.test.utils import datapath, get_tmpfile\n",
        "from gensim.models import KeyedVectors\n",
        "from gensim.scripts.glove2word2vec import glove2word2vec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZDNEbhRrQqQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "9b3125f8-f7c8-48f1-c9ad-b27c9c1d951d"
      },
      "source": [
        "glove_file = datapath('/content/glove.6B.300d.txt')\n",
        "word2vec_glove_file = get_tmpfile(\"glove.6B.300d.word2vec.txt\")\n",
        "glove2word2vec(glove_file, word2vec_glove_file)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(400000, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFqkqedLrQ4C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = KeyedVectors.load_word2vec_format(word2vec_glove_file)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBtZONyarQ_v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_w2v_general(tweet, size, vectors, aggregation='mean'):\n",
        "    vec = np.zeros(size).reshape((1, size))\n",
        "    count = 0.\n",
        "    for word in tweet.split():\n",
        "        try:\n",
        "            vec += vectors[word].reshape((1, size)) #* tfidf[word]\n",
        "            count += 1.\n",
        "        except KeyError:\n",
        "            continue\n",
        "    if aggregation == 'mean':\n",
        "        if count != 0:\n",
        "            vec /= count\n",
        "        return vec\n",
        "    elif aggregation == 'sum':\n",
        "        return vec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5Tl7kTZsCSB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import scale\n",
        "\n",
        "train_vecs_glove_mean = scale(np.concatenate([get_w2v_general(z, 300, model,'mean') for z in X_train]))\n",
        "test_vecs_glove_mean = scale(np.concatenate([get_w2v_general(z, 300, model,'mean') for z in X_test]))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSIib4aivOcB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "236722a0-8174-46ce-9428-075357abdf7b"
      },
      "source": [
        "train_vecs_glove_mean"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.41042086, -3.26646034, -2.12185399, ..., -1.64116441,\n",
              "         1.29226491,  2.17000347],\n",
              "       [-0.23354711,  0.61275259, -0.11670591, ..., -0.72044358,\n",
              "        -0.23813586,  0.14290177],\n",
              "       [-0.80542625,  0.44193173,  1.31955426, ...,  2.35133943,\n",
              "         3.46140278, -1.13922978],\n",
              "       ...,\n",
              "       [ 0.71016532, -0.81178571,  0.91006119, ...,  3.18449576,\n",
              "         0.77984958,  0.01273765],\n",
              "       [ 0.54069084,  0.80937071,  0.14605718, ...,  1.11794501,\n",
              "        -1.0467528 ,  1.95796052],\n",
              "       [-0.66271877,  1.68782755,  0.02669902, ...,  0.08732145,\n",
              "        -0.84801561,  1.59638037]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1lERh-4sCdT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
        "from sklearn.linear_model import RidgeClassifier\n",
        "from sklearn.linear_model import PassiveAggressiveClassifier\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.neighbors import NearestCentroid\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "names = [\"Logistic Regression\", \"KNN\",\"Linear SVC\",\"DC\",\"SGD\",\"RF\",\"LinearSVC with L1-based feature selection\", \n",
        "         \"Bernoulli NB\", \"Ridge Classifier\", \"AdaBoost\", \"Perceptron\",\"Passive-Aggresive\", \"Nearest C4entroid\"]\n",
        "classifiers = [\n",
        "    LogisticRegression(),\n",
        "    KNeighborsClassifier(),\n",
        "    LinearSVC(),\n",
        "    DecisionTreeClassifier(),\n",
        "    SGDClassifier(),\n",
        "    RandomForestClassifier(),\n",
        "    Pipeline([\n",
        "  ('feature_selection', SelectFromModel(LinearSVC(penalty=\"l1\", dual=False))),\n",
        "  ('classification', LinearSVC(penalty=\"l2\"))]),\n",
        "    BernoulliNB(),\n",
        "    RidgeClassifier(),\n",
        "    AdaBoostClassifier(),\n",
        "    Perceptron(),\n",
        "    PassiveAggressiveClassifier(),\n",
        "    NearestCentroid()\n",
        "    ]\n",
        "zipped_clf = zip(names,classifiers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_t74YFOsCqT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from time import time\n",
        "from sklearn import metrics\n",
        "\n",
        "\n",
        "def accuracy_summary(pipeline, x_train, y_train, x_test, y_test):\n",
        "    t0 = time()\n",
        "    sentiment_fit = pipeline.fit(x_train, y_train)\n",
        "    y_pred = sentiment_fit.predict(x_test)\n",
        "    train_test_time = time() - t0\n",
        "    #accuracy = accuracy_score(y_test, y_pred)\n",
        "    accuracy= (metrics.accuracy_score(y_test, y_pred))\n",
        "    #print (\"accuracy score: {0:.2f}%\".format(accuracy*100))\n",
        "    print (\"train and test time: {0:.2f}s\".format(train_test_time))\n",
        "    print (\"-\"*80)\n",
        "    \n",
        "  \n",
        "    p= metrics.precision_score(y_test, y_pred,average= 'weighted')\n",
        "    r = metrics.recall_score(y_test, y_pred,average= 'weighted')\n",
        "    f=metrics.f1_score(y_test, y_pred, average= 'weighted')\n",
        "    \n",
        "    \n",
        "    return accuracy, p,r,f,train_test_time\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjkHqDNnuDeB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b8a1b9ee-f4e7-4899-e2bc-774e2d97636d"
      },
      "source": [
        "def classifier_comparator():\n",
        "    result = []\n",
        "    classifier=zipped_clf\n",
        "    \n",
        "    for n,c in classifier:\n",
        "        checker_pipeline = Pipeline([\n",
        "                     ('classifier', c)\n",
        "        ])\n",
        "        print (\"Validation result for {}\".format(n))\n",
        "        print (c)\n",
        "        #clf_accuracy,p,r,f,tt_time = accuracy_summary(checker_pipeline, train_vecs_dbow, y_train, validation_vecs_dbow, y_valid)\n",
        "        #clf_accuracy,p,r,f,tt_time = accuracy_summary(checker_pipeline, train_vecs_dmc, y_train, validation_vecs_dmc, y_valid)\n",
        "        clf_accuracy,p,r,f,tt_time = accuracy_summary(checker_pipeline, train_vecs_glove_mean, y_train,test_vecs_glove_mean,y_test)\n",
        "\n",
        "        result.append((n,clf_accuracy,p,r,f,tt_time))\n",
        "    return result\n",
        "\n",
        "trigram_result = classifier_comparator()\n",
        "from pandas import ExcelWriter\n",
        "from pandas import ExcelFile\n",
        "\n",
        "df = pd.DataFrame(trigram_result)\n",
        "df.columns=['classifier','acc','p','r','f1','time']\n",
        "\n",
        " \n",
        "writer = ExcelWriter('FB_hindi_test_fasttext_sum.xlsx',engine='openpyxl')\n",
        "df.to_excel(writer,'Sheet1',index=False)\n",
        "writer.save()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation result for Logistic Regression\n",
            "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
            "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
            "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
            "          tol=0.0001, verbose=0, warm_start=False)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train and test time: 1.15s\n",
            "--------------------------------------------------------------------------------\n",
            "Validation result for KNN\n",
            "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
            "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
            "           weights='uniform')\n",
            "train and test time: 4.73s\n",
            "--------------------------------------------------------------------------------\n",
            "Validation result for Linear SVC\n",
            "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
            "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
            "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
            "     verbose=0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train and test time: 1.62s\n",
            "--------------------------------------------------------------------------------\n",
            "Validation result for DC\n",
            "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
            "            max_features=None, max_leaf_nodes=None,\n",
            "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "            min_samples_leaf=1, min_samples_split=2,\n",
            "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
            "            splitter='best')\n",
            "train and test time: 1.24s\n",
            "--------------------------------------------------------------------------------\n",
            "Validation result for SGD\n",
            "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
            "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
            "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=None,\n",
            "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
            "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
            "       validation_fraction=0.1, verbose=0, warm_start=False)\n",
            "train and test time: 0.02s\n",
            "--------------------------------------------------------------------------------\n",
            "Validation result for RF\n",
            "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
            "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
            "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "            min_samples_leaf=1, min_samples_split=2,\n",
            "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
            "            oob_score=False, random_state=None, verbose=0,\n",
            "            warm_start=False)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python2.7/dist-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train and test time: 0.43s\n",
            "--------------------------------------------------------------------------------\n",
            "Validation result for LinearSVC with L1-based feature selection\n",
            "Pipeline(memory=None,\n",
            "     steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
            "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
            "     multi_class='ovr', penalty='l1', random_state=None, tol=0.0001,\n",
            "     verbose=0),\n",
            "        max_features=None, n...ax_iter=1000,\n",
            "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
            "     verbose=0))])\n",
            "train and test time: 8.24s\n",
            "--------------------------------------------------------------------------------\n",
            "Validation result for Bernoulli NB\n",
            "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)\n",
            "train and test time: 0.05s\n",
            "--------------------------------------------------------------------------------\n",
            "Validation result for Ridge Classifier\n",
            "RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
            "        max_iter=None, normalize=False, random_state=None, solver='auto',\n",
            "        tol=0.001)\n",
            "train and test time: 0.05s\n",
            "--------------------------------------------------------------------------------\n",
            "Validation result for AdaBoost\n",
            "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
            "          learning_rate=1.0, n_estimators=50, random_state=None)\n",
            "train and test time: 7.57s\n",
            "--------------------------------------------------------------------------------\n",
            "Validation result for Perceptron\n",
            "Perceptron(alpha=0.0001, class_weight=None, early_stopping=False, eta0=1.0,\n",
            "      fit_intercept=True, max_iter=None, n_iter=None, n_iter_no_change=5,\n",
            "      n_jobs=None, penalty=None, random_state=0, shuffle=True, tol=None,\n",
            "      validation_fraction=0.1, verbose=0, warm_start=False)\n",
            "train and test time: 0.02s\n",
            "--------------------------------------------------------------------------------\n",
            "Validation result for Passive-Aggresive\n",
            "PassiveAggressiveClassifier(C=1.0, average=False, class_weight=None,\n",
            "              early_stopping=False, fit_intercept=True, loss='hinge',\n",
            "              max_iter=None, n_iter=None, n_iter_no_change=5, n_jobs=None,\n",
            "              random_state=None, shuffle=True, tol=None,\n",
            "              validation_fraction=0.1, verbose=0, warm_start=False)\n",
            "train and test time: 0.03s\n",
            "--------------------------------------------------------------------------------\n",
            "Validation result for Nearest C4entroid\n",
            "NearestCentroid(metric='euclidean', shrink_threshold=None)\n",
            "train and test time: 0.01s\n",
            "--------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in Perceptron in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python2.7/dist-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in PassiveAggressiveClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRyl28YruDnq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "5e81b2ed-3505-40c2-b1cc-8a045598b95e"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            classifier       acc         p         r        f1      time\n",
              "0  Logistic Regression  0.964111  0.964986  0.964111  0.964470  1.139833\n",
              "1                  KNN  0.963567  0.962799  0.963567  0.963012  5.130893\n",
              "2           Linear SVC  0.946710  0.953405  0.946710  0.948815  0.531015\n",
              "3                   DC  0.924959  0.926886  0.924959  0.925832  1.072232\n",
              "4                  SGD  0.954867  0.953537  0.954867  0.953834  0.023961"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>classifier</th>\n",
              "      <th>acc</th>\n",
              "      <th>p</th>\n",
              "      <th>r</th>\n",
              "      <th>f1</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>0.964111</td>\n",
              "      <td>0.964986</td>\n",
              "      <td>0.964111</td>\n",
              "      <td>0.964470</td>\n",
              "      <td>1.139833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>KNN</td>\n",
              "      <td>0.963567</td>\n",
              "      <td>0.962799</td>\n",
              "      <td>0.963567</td>\n",
              "      <td>0.963012</td>\n",
              "      <td>5.130893</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Linear SVC</td>\n",
              "      <td>0.946710</td>\n",
              "      <td>0.953405</td>\n",
              "      <td>0.946710</td>\n",
              "      <td>0.948815</td>\n",
              "      <td>0.531015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>DC</td>\n",
              "      <td>0.924959</td>\n",
              "      <td>0.926886</td>\n",
              "      <td>0.924959</td>\n",
              "      <td>0.925832</td>\n",
              "      <td>1.072232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>SGD</td>\n",
              "      <td>0.954867</td>\n",
              "      <td>0.953537</td>\n",
              "      <td>0.954867</td>\n",
              "      <td>0.953834</td>\n",
              "      <td>0.023961</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIzviYhzuDz5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrIUfpUYuDcc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1Zk24vQenaM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "153dca99-6bb7-4b23-eb39-85509cd9f6b8"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn import metrics\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "model_SVM = SVC()\n",
        "model_SVM.fit(x_train, y_train)\n",
        "y_pred_SVM = model_SVM.predict(x_test)\n",
        "print(\"SVM\")\n",
        "print(\"Accuracy score =\", accuracy_score(y_test, y_pred_SVM))\n",
        "print(metrics.classification_report(y_test, y_pred_SVM))\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf = RandomForestClassifier(n_estimators=100,max_depth=None,min_samples_split=2, random_state=0)\n",
        "rf.fit(x_train,y_train)\n",
        "y_pred_rf = rf.predict(x_test)\n",
        "print(\"random\")\n",
        "print(\"Accuracy score =\", accuracy_score(y_test, y_pred_rf))\n",
        "print(metrics.classification_report(y_test, y_pred_rf))\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "LR = LogisticRegression()\n",
        "LR.fit(x_train,y_train)\n",
        "y_pred_LR = LR.predict(x_test)\n",
        "print(\"Logistic Regression\")\n",
        "print(\"Accuracy score =\", accuracy_score(y_test, y_pred_LR))\n",
        "print(metrics.classification_report(y_test, y_pred_LR ))\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "neigh = KNeighborsClassifier(n_neighbors = 5)\n",
        "neigh.fit(x_train,y_train)\n",
        "y_pred_KNN = neigh.predict(x_test)\n",
        "print(\"KNN\")\n",
        "print(\"Accuracy score =\", accuracy_score(y_test, y_pred_KNN))\n",
        "print(metrics.classification_report(y_test, y_pred_KNN ))\n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "naive = GaussianNB()\n",
        "naive.fit(x_train.toarray(),y_train)\n",
        "y_pred_naive = naive.predict(x_test.toarray())\n",
        "print(\"Naive Bayes\")\n",
        "print(\"Accuracy score =\", accuracy_score(y_test, y_pred_naive))\n",
        "print(metrics.classification_report(y_test, y_pred_naive ))\n",
        "\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "gradient = GradientBoostingClassifier(n_estimators=100,max_depth=None,min_samples_split=2, random_state=0)\n",
        "gradient.fit(x_train,y_train)\n",
        "y_pred_gradient = gradient.predict(x_test)\n",
        "print(\"Gradient Boosting\")\n",
        "print(\"Accuracy score =\", accuracy_score(y_test, y_pred_gradient))\n",
        "print(metrics.classification_report(y_test, y_pred_gradient ))\n",
        "\n",
        "    \n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "decision = DecisionTreeClassifier()\n",
        "decision.fit(x_train,y_train)\n",
        "y_pred_decision = decision.predict(x_test)\n",
        "print(\"Decision Tree\")\n",
        "print(\"Accuracy score =\", accuracy_score(y_test, y_pred_decision))\n",
        "print(metrics.classification_report(y_test, y_pred_decision ))\n",
        "    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SVM\n",
            "('Accuracy score =', 0.866231647634584)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      1.00      0.93      1593\n",
            "           1       0.00      0.00      0.00       246\n",
            "\n",
            "   micro avg       0.87      0.87      0.87      1839\n",
            "   macro avg       0.43      0.50      0.46      1839\n",
            "weighted avg       0.75      0.87      0.80      1839\n",
            "\n",
            "random\n",
            "('Accuracy score =', 0.9804241435562806)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99      1593\n",
            "           1       1.00      0.85      0.92       246\n",
            "\n",
            "   micro avg       0.98      0.98      0.98      1839\n",
            "   macro avg       0.99      0.93      0.95      1839\n",
            "weighted avg       0.98      0.98      0.98      1839\n",
            "\n",
            "Logistic Regression\n",
            "('Accuracy score =', 0.9717237629146275)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.98      1593\n",
            "           1       0.99      0.80      0.88       246\n",
            "\n",
            "   micro avg       0.97      0.97      0.97      1839\n",
            "   macro avg       0.98      0.90      0.93      1839\n",
            "weighted avg       0.97      0.97      0.97      1839\n",
            "\n",
            "KNN\n",
            "('Accuracy score =', 0.9037520391517129)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      1.00      0.95      1593\n",
            "           1       1.00      0.28      0.44       246\n",
            "\n",
            "   micro avg       0.90      0.90      0.90      1839\n",
            "   macro avg       0.95      0.64      0.69      1839\n",
            "weighted avg       0.91      0.90      0.88      1839\n",
            "\n",
            "Naive Bayes\n",
            "('Accuracy score =', 0.9059271343121261)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.91      0.94      1593\n",
            "           1       0.60      0.91      0.72       246\n",
            "\n",
            "   micro avg       0.91      0.91      0.91      1839\n",
            "   macro avg       0.79      0.91      0.83      1839\n",
            "weighted avg       0.93      0.91      0.91      1839\n",
            "\n",
            "Gradient Boosting\n",
            "('Accuracy score =', 0.9733550842849374)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.98      1593\n",
            "           1       0.93      0.86      0.90       246\n",
            "\n",
            "   micro avg       0.97      0.97      0.97      1839\n",
            "   macro avg       0.96      0.93      0.94      1839\n",
            "weighted avg       0.97      0.97      0.97      1839\n",
            "\n",
            "Decision Tree\n",
            "('Accuracy score =', 0.9679173463839043)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.98      1593\n",
            "           1       0.91      0.85      0.88       246\n",
            "\n",
            "   micro avg       0.97      0.97      0.97      1839\n",
            "   macro avg       0.94      0.92      0.93      1839\n",
            "weighted avg       0.97      0.97      0.97      1839\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sk5zs952fdM-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}